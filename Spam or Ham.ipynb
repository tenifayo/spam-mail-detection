{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spam Detection using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mail type</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mail type                                            message\n",
       "0          ham  Go until jurong point, crazy.. Available only ...\n",
       "1          ham                      Ok lar... Joking wif u oni...\n",
       "2         spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3          ham  U dun say so early hor... U c already then say...\n",
       "4          ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...        ...                                                ...\n",
       "5567      spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568       ham               Will ü b going to esplanade fr home?\n",
       "5569       ham  Pity, * was in mood for that. So...any other s...\n",
       "5570       ham  The guy did some bitching but I acted like i'd...\n",
       "5571       ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam_or_ham.csv',encoding= 'latin1')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: mail type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mail type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the labels\n",
    "le = LabelEncoder()\n",
    "df['mail type'] = le.fit_transform(df['mail type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]+', ' ',text) #to remove punctuation\n",
    "    text = re.sub(r'\\d+(\\.\\d+)?', ' ', text)#to remove numbers\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])#to remove stopwords\n",
    "    text = ' '.join([lemmatizer.lemmatize(y,'v') for y in text.split()]) #to lemmatize\n",
    "    text = ' '.join([lemmatizer.lemmatize(y,'n') for y in text.split()]) #to lemmatize\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_message'] = df['message'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mail type</th>\n",
       "      <th>message</th>\n",
       "      <th>cleaned_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah think go usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mail type                                            message  \\\n",
       "0          0  Go until jurong point, crazy.. Available only ...   \n",
       "1          0                      Ok lar... Joking wif u oni...   \n",
       "2          1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3          0  U dun say so early hor... U c already then say...   \n",
       "4          0  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                     cleaned_message  \n",
       "0  go jurong point crazy available bugis n great ...  \n",
       "1                              ok lar joke wif u oni  \n",
       "2  free entry wkly comp win fa cup final tkts st ...  \n",
       "3                u dun say early hor u c already say  \n",
       "4                nah think go usf live around though  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(df[\"cleaned_message\"], df[\"mail type\"], \n",
    "                                                                      test_size=0.2, random_state=42,\n",
    "                                                                      stratify=df['mail type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary\n",
    "word_counts = Counter([word for text in train_texts for word in text.split(' ') ])\n",
    "vocab = {word: idx + 1 for idx, (word, _) in enumerate(word_counts.most_common())}  # Start indexing from 1\n",
    "\n",
    "# Convert text to sequence of indices\n",
    "def text_to_sequence(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    seq = [vocab.get(word, 0) for word in tokens]\n",
    "    return  seq \n",
    "\n",
    "train_sequences = [text_to_sequence(text) for text in train_texts]\n",
    "test_sequences = [text_to_sequence(text) for text in test_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 1115)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sequences), len(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 80  # Truncate or pad sequences to this length\n",
    "\n",
    "def pad_sequences(sequences, max_len=MAX_LEN):\n",
    "    \"\"\"This function takes a sequence and either truncates it or pads it with zeros \n",
    "    to make it the same length as the max_len\"\"\"\n",
    "    return [seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in sequences]\n",
    "\n",
    "train_sequences = pad_sequences(train_sequences)\n",
    "test_sequences = pad_sequences(test_sequences)\n",
    "\n",
    "# Convert the sequence to tensors\n",
    "train_tensor = torch.tensor(train_sequences, dtype=torch.long)\n",
    "test_tensor = torch.tensor(test_sequences, dtype=torch.long)\n",
    "train_labels_tensor = torch.tensor(train_labels.values, dtype=torch.float32)\n",
    "test_labels_tensor = torch.tensor(test_labels.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Custom pytorch Dataset\n",
    "class MessageTextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = MessageTextDataset(train_tensor, train_labels_tensor)\n",
    "test_dataset = MessageTextDataset(test_tensor, test_labels_tensor)\n",
    "\n",
    "# Create dataloaders\n",
    "BATCH_SIZE = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spam classifier model using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleRNNModel(\n",
      "  (embedding): Embedding(5706, 32)\n",
      "  (rnn1): RNN(32, 32, batch_first=True)\n",
      "  (dropout1): Dropout(p=0.2, inplace=False)\n",
      "  (rnn2): RNN(32, 64, batch_first=True)\n",
      "  (dropout2): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=5120, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Spam classifier model using RNN\n",
    "\n",
    "class SimpleRNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=32, hidden_dim1=32, hidden_dim2=64, sequence_length=80):\n",
    "        super(SimpleRNNModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "        \n",
    "        self.rnn1 = nn.RNN(input_size=embedding_dim, hidden_size=hidden_dim1, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.2) \n",
    "\n",
    "        self.rnn2 = nn.RNN(input_size=hidden_dim1, hidden_size=hidden_dim2, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim2 * sequence_length, 1)  \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        x, _ = self.rnn1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x, _ = self.rnn2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = x.reshape(x.shape[0], -1)  # Flatten\n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "vocab_size = len(vocab) + 1 \n",
    "sequence_length = 80\n",
    "model = SimpleRNNModel(vocab_size=vocab_size, sequence_length=sequence_length)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2262\n",
      "Epoch 2, Loss: 0.1171\n",
      "Epoch 3, Loss: 0.0758\n",
      "Epoch 4, Loss: 0.0578\n",
      "Epoch 5, Loss: 0.0374\n",
      "Epoch 6, Loss: 0.0310\n",
      "Epoch 7, Loss: 0.0253\n",
      "Epoch 8, Loss: 0.0174\n",
      "Epoch 9, Loss: 0.0151\n",
      "Epoch 10, Loss: 0.0096\n",
      "Epoch 11, Loss: 0.0088\n",
      "Epoch 12, Loss: 0.0086\n",
      "Epoch 13, Loss: 0.0029\n",
      "Epoch 14, Loss: 0.0014\n",
      "Epoch 15, Loss: 0.0018\n",
      "Epoch 16, Loss: 0.0044\n",
      "Epoch 17, Loss: 0.0023\n",
      "Epoch 18, Loss: 0.0041\n",
      "Epoch 19, Loss: 0.0004\n",
      "Epoch 20, Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "EPOCHS = 20\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for texts, labels in train_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts)\n",
    "        labels = labels.view(-1, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9812\n",
      "Precision: 0.9638\n",
      "Recall: 0.8926\n",
      "F1 Score: 0.9268\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for texts, labels in test_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        preds = model(texts).squeeze().round() \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds)\n",
    "recall = recall_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99       966\n",
      "         1.0       0.96      0.89      0.93       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.94      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(all_labels, all_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
